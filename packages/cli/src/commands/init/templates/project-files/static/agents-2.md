# Pipes SDK Agent Playbook

Use this file to help a coding agent deliver a working Pipes SDK pipeline quickly and safely.
It is intentionally concise, with examples at the end.

## Mission
Ship a pipeline that:
- Builds from the generated project structure
- Streams from SQD Portal
- Decodes/transforms only what is required
- Persists correctly with rollback safety

## Success criteria
- `src/index.ts` runs without edits outside `src/`
- Decoding matches the chosen network (EVM or Solana)
- Data is persisted with proper rollback handling
- Ranges and queries are minimal and scoped

## Project map
- `src/index.ts`: main pipeline entry
- `src/contracts/`: generated ABIs and typed decoders
- `src/utils/`: ClickHouse helpers (only when ClickHouse sink is chosen)
- `migrations/`: SQL for ClickHouse or PostgreSQL
- `.env`, `docker-compose.yml`: local databases and credentials

## Decide the mode first
This project is either:
- **EVM**: uses `@subsquid/pipes/evm`
- **Solana**: uses `@subsquid/pipes/solana`

Check `src/index.ts` imports and the generated template before making changes.

## Core pipeline shape
Pipes SDK is a stream:
1) **Portal source**: fetches chain data from SQD Portal
2) **Decoder**: narrows and types the data (events or instructions)
3) **Transformer** (optional): joins or reshapes data
4) **Target**: persists to ClickHouse/PostgreSQL or custom sink

Keep the pipeline linear and declarative. If combining multiple decoders, use `pipeComposite`.

## Query discipline
- Request only fields you need (use Query Builder if you need more than logs/events)
- Use explicit `range` and minimize breadth
- Avoid decoding entire datasets without filters

## Persistence discipline
When persisting:
- Use `onStart` to ensure tables exist
- Use `onData` to batch inserts
- Use `onRollback` with the provided cursor to delete rows above the safe point

## Stateful indexing
For long-running jobs, guard against forks:
- Always wire rollback logic in the target
- Treat the cursor as the source of truth for safety

## EVM-specific notes
- Use `evmPortalSource` + `evmDecoder`
- `commonAbis.erc20` is available for ERC20 transfers
- For custom contracts, generate ABIs into `src/contracts/`
- Use `factory` + `factorySqliteDatabase` for dynamic contract sets

## Solana-specific notes
- Use `solanaPortalSource`
- Use instruction decoding for program-specific data
- Query builder is the safe way to select accounts, programs, and fields
- Use the latency watcher only when debugging performance

## Quality-of-life patterns
- Add log summaries per batch rather than per event
- Prefer typed events/instructions over raw logs
- Use composite pipes when processing multiple streams in parallel

## Docs entry points
- Quickstart: https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/quickstart
- Introduction: https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/introduction
- Core concepts: https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/core-concepts/overview
- Event decoding: https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/guides/event-decoding
- Factory pattern: https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/guides/factory-pattern
- Data persistence: https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/guides/data-persistence

## Examples (trimmed)

### Generate ABIs for custom contracts
Use the ABI type generator when you need typed events for a contract that is not covered by `commonAbis`.
Generated files should live under `src/contracts/` so they can be imported in `src/index.ts`.

```sh
npx @subsquid/evm-typegen@latest src/contracts \
  0x000000000004444c5dc75cB358380D2e3dE08A90 \
  --chain-id 1
```

### Basic EVM stream
Creates a Portal source, decodes ERC20 transfers with the built-in ABI, and logs the batch size.

```ts
import { commonAbis, evmDecoder, evmPortalSource } from '@subsquid/pipes/evm'

async function main() {
  const stream = evmPortalSource({
    portal: 'https://portal.sqd.dev/datasets/ethereum-mainnet',
  }).pipe(
    evmDecoder({
      range: { from: 'latest' },
      events: {
        transfers: commonAbis.erc20.events.Transfer,
      },
    }),
  )

  for await (const { data } of stream) {
    console.log(data.transfers.length)
  }
}

void main()
```

### Factory pattern (EVM)
Tracks pools created by a factory contract, then decodes swap events only for those pools.
This is the standard approach for protocols with dynamic contract creation (e.g., Uniswap V3).

```ts
import { evmDecoder, evmPortalSource, factory, factorySqliteDatabase } from '@subsquid/pipes/evm'
import { events as factoryAbi } from './abi/uniswap.v3/factory'
import { events as swapsAbi } from './abi/uniswap.v3/swaps'

async function main() {
  const stream = evmPortalSource({
    portal: 'https://portal.sqd.dev/datasets/ethereum-mainnet',
  }).pipe(
    evmDecoder({
      range: { from: '12,369,621' },
      contracts: factory({
        address: '0x1f98431c8ad98523631ae4a59f267346ea31f984',
        event: factoryAbi.PoolCreated,
        parameter: 'pool',
        database: factorySqliteDatabase({ path: './uniswap3-eth-pools.sqlite' }),
      }),
      events: {
        swaps: swapsAbi.Swap,
      },
    }),
  )

  for await (const { data } of stream) {
    console.log(`parsed ${data.swaps.length} swaps`)
  }
}

void main()
```

### ClickHouse target
Decodes ERC20 transfers, maps them to rows, and writes them to ClickHouse with rollback safety.

```ts
import { createClient } from '@clickhouse/client'
import { commonAbis, evmDecoder, evmPortalSource } from '@subsquid/pipes/evm'
import { clickhouseTarget } from '@subsquid/pipes/targets/clickhouse'

async function main() {
  await evmPortalSource({
    portal: 'https://portal.sqd.dev/datasets/ethereum-mainnet',
  })
    .pipe(
      evmDecoder({
        range: { from: 'latest' },
        events: {
          transfers: commonAbis.erc20.events.Transfer,
        },
      }),
    )
    .pipe((data) =>
      data.transfers.map((t) => ({
        block_number: t.block.number,
        token: t.contract,
        from: t.event.from,
        to: t.event.to,
        amount: t.event.value.toString(),
      })),
    )
    .pipeTo(
      clickhouseTarget({
        client: createClient({
          username: 'default',
          password: 'password',
          url: 'http://localhost:8123',
        }),
        onStart: async ({ store }) => {
          await store.command({
            query: `
              CREATE TABLE IF NOT EXISTS erc20_transfers (
                block_number  UInt64,
                timestamp     DateTime64(3) CODEC (DoubleDelta, ZSTD),
                token         String,
                from          String,
                to            String,
                amount        UInt256
              )
              ENGINE = MergeTree
              ORDER BY block_number
            `,
          })
        },
        onData: async ({ data, store }) => {
          await store.insert({
            table: 'erc20_transfers',
            values: data,
            format: 'JSONEachRow',
          })
        },
        onRollback: async ({ safeCursor, store }) => {
          await store.removeAllRows({
            tables: ['erc20_transfers'],
            where: `block_number > {latest:UInt32}`,
            params: { latest: safeCursor.number },
          })
        },
      }),
    )
}

void main()
```
